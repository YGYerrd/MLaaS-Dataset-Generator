# MLaaS Data Generator

This package converts the original `MLaaS_Data_Generator.ipynb` notebook into a small
Python package.  The goal is to provide a repeatable way to generate synthetic
client records for experiments with Adaptive MLaaS.

The generator performs a lightweight federated-learning loop. Local model
weights for each client and the aggregated global weights are written to a
`weights/` directory for every round.

Multiple round metrics can be combined into one dataframe for further evaluation

## Usage
### Subcommands
generate — run the federated loop and write a per-round, per-client CSV.
merge — combine multiple CSVs into a single file with optional de-duplication and a sequential ID.

### Flags
--clients INT — number of clients.

--dataset {fashion_mnist,mnist} — dataset to use.

--output PATH — output CSV filename (written under outputs/runs/).

--strategy {iid,quantity_skew,dirichlet,shard,label_per_client,custom}

--distribution-param FLOAT — meaning depends on strategy (see below).
iid: ignored.
quantity_skew: Dirichlet α over client sizes (higher α → more even).
dirichlet: Dirichlet α over labels per client (higher α → more even).
shard: shards_per_client (int). Data sorted by label, split into shards, randomly assigned.
label_per_client: k labels per client (int, 1…#classes).
custom: ignored; use --distribution JSON. (Auto-extend/shrink to match --clients happens inside the splitter.)

--distribution PATH.json — only for --strategy custom; points to per-client label counts.

Optional dataset downsampling before splitting:
--sample-size INT or --sample-frac FLOAT (use one).


### Run Examples
Minimal Run (IID)
```bash
python -m mlaas_data_generator.cli generate --clients 5 --dataset fashion_mnist --strategy iid --output clients.csv
```

Quantity Skew 
```bash
python -m mlaas_data_generator.cli generate --clients 5 --strategy quantity_skew --distribution-param 0.3 --output qskew.csv
```

Dirichlet Label Skew
```bash
python -m mlaas_data_generator.cli generate --clients 10 --strategy dirichlet --distribution-param 0.2 --output dirichlet.csv
```

Loose Shard-based partitioning
```bash
python -m mlaas_data_generator.cli generate --clients 5 --strategy shard --distribution-param 2 --output shard.csv
```

K labels per client
```bash
python -m mlaas_data_generator.cli generate --clients 5 --strategy label_per_client --distribution-param 2 --output klabels.csv
```

Custom distributions (JSON file)
```bash
python -m mlaas_data_generator.cli generate --clients 5 --strategy custom --distribution custom_distributions.json --output custom.csv

```

Downsampling
```bash
# Use 30k samples
python -m mlaas_data_generator.cli generate --sample-size 30000 ...

# Use 50% of the dataset
python -m mlaas_data_generator.cli generate --sample-frac 0.5 ...
```
Modifying the model attributes (example calls)
```bash
python -m mlaas_data_generator.cli generate --clients 5 --dataset fashion_mnist --strategy iid --hidden-layers "64,32" --activation relu --optimizer adam --dropout 0.1 --weight-decay 0.0 --epochs-per-round 5 --batch-size 32 --learning-rate 0.01 --output run_simple.csv

python -m mlaas_data_generator.cli generate --clients 10 --dataset mnist --strategy quantity_skew --distribution-param 0.5 --hidden-layers "128,64,32" --activation relu --dropout 0.3 --weight-decay 1e-4 --optimizer adamw --epochs-per-round 3 --batch-size 64 --learning-rate 0.001 --output run_deep.csv

python -m mlaas_data_generator.cli generate \
  --clients 20 \
  --dataset fashion_mnist \
  --strategy shard \
  --distribution-param 2 \
  --hidden-layers "256,128" \
  --activation tanh \
  --dropout 0.2 \
  --weight-decay 0.0 \
  --optimizer sgd \
  --epochs-per-round 5 \
  --batch-size 128 \
  --learning-rate 0.05 \
  --output run_shard.csv

```

# Merge explicit files 
python -m mlaas_data_generator.cli merge  outputs/runs/clients.csv outputs/runs/FMNIST_clients.csv --output merged.csv --dedupe
    # Or globs
python -m mlaas_data_generator.cli merge ""outputs/runs/*.csv" --output merged.csv

```

Use `--clients *num_clients*` to specify the number of clients wanted.
Use `--dataset *dataset_name*` to switch to the specified dataset.
Specify `--distribution custom_distributions.json` to use a custom distributed dataset.
use `--output *filename*.csv` to specify the output files name. 


The command downloads the chosen dataset, trains a small model for each
client and writes the resulting metrics into `clients.csv`.
