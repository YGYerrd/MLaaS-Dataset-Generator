import numpy as np

def _is_multilabel_sample(value):
    return isinstance(value, (list, tuple, set, np.ndarray))


def _encode_multilabel_targets(train_labels, test_labels, label_feat):
    try:
        from datasets import ClassLabel, Sequence
    except Exception:
        ClassLabel = None
        Sequence = None

    num_classes = None
    label_mapping = None

    if (
        ClassLabel is not None
        and Sequence is not None
        and isinstance(label_feat, Sequence)
        and isinstance(getattr(label_feat, "feature", None), ClassLabel)
    ):
        class_label = label_feat.feature
        num_classes = int(class_label.num_classes)
        if getattr(class_label, "names", None):
            label_mapping = {str(name): int(i) for i, name in enumerate(class_label.names)}

    if num_classes is None:
        max_label = -1
        for ys in (train_labels, test_labels):
            for row in ys:
                for idx in row:
                    max_label = max(max_label, int(idx))
        num_classes = max_label + 1

    if num_classes <= 0:
        raise ValueError("Could not infer num_classes for multi-label targets")

    def to_multi_hot(rows):
        out = np.zeros((len(rows), num_classes), dtype="float32")
        for i, row in enumerate(rows):
            for idx in row:
                j = int(idx)
                if j < 0 or j >= num_classes:
                    raise ValueError(f"Label index out of range for multi-label target: {j}")
                out[i, j] = 1.0
        return out

    y_train = to_multi_hot(train_labels)
    y_test = to_multi_hot(test_labels)

    if label_mapping is None:
        label_mapping = {str(i): i for i in range(num_classes)}

    return y_train, y_test, num_classes, label_mapping

def preprocess_hf_text_sequence(
    train,
    test,
    meta,
    *,
    hf_model_id,
    text_column="text",
    label_column="label",
):
    ds_train, _ = train
    ds_test, _ = test

    cols = set(ds_train.column_names)

    # ----------------------------
    # Resolve text column(s)
    # ----------------------------
    is_pair = False
    if isinstance(text_column, str):
        if text_column not in cols:
            raise ValueError(f"Missing text_column '{text_column}' in dataset '{meta.get('hf_id')}'")
        text_col_1 = text_column
        text_col_2 = None
    elif isinstance(text_column, (list, tuple)) and len(text_column) == 2:
        is_pair = True
        text_col_1 = text_column[0]
        text_col_2 = text_column[1]
        if text_col_1 not in cols or text_col_2 not in cols:
            raise ValueError(
                f"Missing text_column pair {text_column} in dataset '{meta.get('hf_id')}'. "
                f"Available: {sorted(cols)}"
            )
    else:
        raise ValueError("text_column must be a string or a list/tuple of length 2 for text pairs.")

    if label_column not in cols:
        raise ValueError(f"Missing label_column '{label_column}' in dataset '{meta.get('hf_id')}'")

    # ----------------------------
    # Labels -> int32, mapping
    # ----------------------------
    try:
        from datasets import ClassLabel
    except Exception:
        ClassLabel = None

    label_feat = ds_train.features.get(label_column)

    train_labels = list(ds_train[label_column])
    test_labels = list(ds_test[label_column])

    first_non_null = next((v for v in train_labels if v is not None), None)
    is_multilabel = _is_multilabel_sample(first_non_null)

    if is_multilabel:
        y_train, y_test, num_classes, label_mapping = _encode_multilabel_targets(
            train_labels,
            test_labels,
            label_feat,
        )
    elif ClassLabel is not None and isinstance(label_feat, ClassLabel):
        num_classes = int(label_feat.num_classes)
        y_train = np.asarray(train_labels, dtype="int32")
        y_test = np.asarray(test_labels, dtype="int32")
        label_mapping = {str(i): i for i in range(num_classes)}
    else:
        uniq = {}
        y_train_list = []
        for v in train_labels:
            if v not in uniq:
                uniq[v] = len(uniq)
            y_train_list.append(uniq[v])

        y_test_list = []
        for v in ds_test[label_column]:
            if v not in uniq:
                raise ValueError(f"Unseen label in test split: {v!r}")
            y_test_list.append(uniq[v])

        y_train = np.asarray(y_train_list, dtype="int32")
        y_test = np.asarray(y_test_list, dtype="int32")
        num_classes = int(len(uniq))
        label_mapping = {str(k): int(v) for k, v in uniq.items()}

    # ----------------------------
    # Tokenise
    # ----------------------------
    try:
        from transformers import AutoTokenizer
    except Exception as e:
        raise ImportError(
            "HF text preprocessing requires 'transformers'. Install with: pip install transformers"
        ) from e

    max_length = int(meta.get("max_length", 128))
    try:
        tokenizer = AutoTokenizer.from_pretrained(hf_model_id, use_fast=True)
    except Exception:
        tokenizer = AutoTokenizer.from_pretrained(hf_model_id, use_fast=False)

    if not is_pair:
        texts_train = list(ds_train[text_col_1])
        texts_test = list(ds_test[text_col_1])

        enc_train = tokenizer(
            texts_train,
            truncation=True,
            padding="max_length",
            max_length=max_length,
            return_tensors="np",
        )
        enc_test = tokenizer(
            texts_test,
            truncation=True,
            padding="max_length",
            max_length=max_length,
            return_tensors="np",
        )
    else:
        texts1_train = list(ds_train[text_col_1])
        texts2_train = list(ds_train[text_col_2])
        texts1_test = list(ds_test[text_col_1])
        texts2_test = list(ds_test[text_col_2])

        enc_train = tokenizer(
            texts1_train,
            texts2_train,
            truncation=True,
            padding="max_length",
            max_length=max_length,
            return_tensors="np",
        )
        enc_test = tokenizer(
            texts1_test,
            texts2_test,
            truncation=True,
            padding="max_length",
            max_length=max_length,
            return_tensors="np",
        )

    X_train = {
        "input_ids": enc_train["input_ids"].astype("int32"),
        "attention_mask": enc_train["attention_mask"].astype("int32"),
    }
    X_test = {
        "input_ids": enc_test["input_ids"].astype("int32"),
        "attention_mask": enc_test["attention_mask"].astype("int32"),
    }

    # Some models return token_type_ids for pairs; include if present
    if "token_type_ids" in enc_train:
        X_train["token_type_ids"] = enc_train["token_type_ids"].astype("int32")
        X_test["token_type_ids"] = enc_test["token_type_ids"].astype("int32")

    x_keys = list(X_train.keys())

    meta2 = dict(meta)
    meta2.update({
        "input_shape": (max_length,),
        "num_classes": num_classes,
        "label_mapping": label_mapping,
        "text_column": text_column,       # keep original user-supplied shape (str or [a,b])
        "label_column": label_column,
        "hf_model_id": hf_model_id,
        "x_format": "dict",
        "x_keys": x_keys,
        "label_granularity": "sequence",
        "hf_task": "sequence_classification",
        "is_multilabel": bool(is_multilabel),
        "classification_type": "multilabel" if is_multilabel else "single_label",
        "modality": "text",
    })

    return (X_train, y_train), (X_test, y_test), meta2