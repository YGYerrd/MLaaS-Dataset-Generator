# -*- coding: utf-8 -*-
"""Experiment 2: Evaluating MLaaS Composition Quality_v2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fJ1XZizvCxb2zsjjmGMQs8QHd2Jft6TV
"""

# ============================================================
# STEP 0: Imports and file paths
# ============================================================
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
FULL_MLAAS_PATH = "/content/MLaaS Dataset Generator.csv"
INCOMPLETE_MLAAS_PATH = "/content/MLaaS Incomplete Data.csv"
# ============================================================
# STEP 1: Load datasets
# ============================================================
df_full = pd.read_csv(FULL_MLAAS_PATH)
df_incomp = pd.read_csv(INCOMPLETE_MLAAS_PATH)
df_full

df_full['dataset'].value_counts()

df_incomp['model_type'].value_counts()

# =============================
# Filter df_full for MNIST + Fashion-MNIST
# =============================
valid_datasets = ["fashion_mnist", "mnist","digits"]
df_full_filtered = df_full[df_full["dataset"].isin(valid_datasets)].copy()

print("Filtered df_full shape:", df_full_filtered.shape)
print(df_full_filtered["dataset"].value_counts())
df_full_filtered

# =============================
# Filter df_incomp for MNIST/Fashion-MNIST model types
# =============================
valid_models = ["Minist64","Minist32","Minist16",
                "FMinist64","FMinist32","FMinist16"]

# If the dataset may have inconsistent case, normalize first:
df_incomp["model_type"] = df_incomp["model_type"].astype(str).str.strip()

df_incomp_filtered = df_incomp[df_incomp["model_type"].isin(valid_models)].copy()

print("Filtered df_incomp shape:", df_incomp_filtered.shape)
print(df_incomp_filtered["model_type"].value_counts())
df_incomp_filtered

df_full_filtered.to_csv("filtered dataset.csv")

df_incomp_filtered.columns

df_full_filtered['dataset'].value_counts()

"""**Adaptive Composability scores**
---
"""

import numpy as np
import pandas as pd

# ------------------------------------------------
# 0. Load dataset
# ------------------------------------------------
df = pd.read_csv("filtered dataset.csv")

# ------------------------------------------------
# 1. Averages for OLD scoring
# ------------------------------------------------
avg_time       = df["computation_time"].mean()
avg_quality    = df["metric_score"].mean()
avg_volume     = df["data_volume"].mean()
avg_reliability = df["global_score"].mean()  # not used directly, but kept for logical completeness

# ------------------------------------------------
# 2. Global reference distribution
# ------------------------------------------------
dist_list = df["data_distribution"].apply(lambda x: np.array(list(eval(x).values())))
global_ref_dist = np.mean(np.vstack(dist_list), axis=0)

# ------------------------------------------------
# 3. OLD subscores
# ------------------------------------------------
def S_dist(dist):
    return 1 / (1 + np.linalg.norm(dist - global_ref_dist))

def S_time(t):
    return avg_time / (t + avg_time)

def S_quality(q):
    return 1 / (1 + abs(q - avg_quality))

def S_rel(r):
    return r   # expected 0â€“1 score

def S_volume(v):
    return v / (v + avg_volume)

# ------------------------------------------------
# 4. Compute OLD composability score (raw)
# ------------------------------------------------
old_scores = []
for idx, row in df.iterrows():
    dist = np.array(list(eval(row["data_distribution"]).values()))

    score = np.mean([
        S_dist(dist),
        S_time(row["computation_time"]),
        S_quality(row["metric_score"]),
        S_rel(row["global_score"]),
        S_volume(row["data_volume"])
    ])

    old_scores.append(score)

df["Old_Composability_Score_raw"] = old_scores

# ------------------------------------------------
# 5. NEW additional derived metrics
# ------------------------------------------------
df["train_eff"] = df["metric_score"] / (df["cpu_time_s"] + 1)
df["comm_eff"]  = df["metric_score"] / (df["comm_bytes_up"] + df["comm_bytes_down"] + 1)
df["mem_eff"]   = df["metric_score"] / (df["memory_used_mb"] + 1)
df["comp_eff"]  = df["metric_score"] / (df["computation_time"] + 1)
df["data_util"] = df["metric_score"] * df["data_volume"]
df["model_norm"] = df["metric_score"] / (df["params_count"] + 1)

# Averages for new normalization
avg_train = df["train_eff"].max()
avg_comm  = df["comm_eff"].max()
avg_mem   = df["mem_eff"].max()
avg_comp2 = df["comp_eff"].max()
avg_data2 = df["data_util"].max()
avg_model = df["model_norm"].max()

def norm_score(x, avg):
    return x / (x + avg + 1e-9)

# ------------------------------------------------
# 6. Compute NEW composability score (raw)
# ------------------------------------------------
new_scores = []
for idx, row in df.iterrows():
    dist = np.array(list(eval(row["data_distribution"]).values()))

    subscores = [
        # === OLD subscores ===
        S_dist(dist),
        S_time(row["computation_time"]),
        S_quality(row["metric_score"]),
        S_rel(row["global_score"]),
        S_volume(row["data_volume"]),

        # === NEW subscores ===
        norm_score(row["train_eff"], avg_train),
        norm_score(row["comm_eff"],  avg_comm),
        norm_score(row["mem_eff"],   avg_mem),
        norm_score(row["comp_eff"],  avg_comp2),
        norm_score(row["data_util"], avg_data2),
        norm_score(row["model_norm"], avg_model),
    ]

    new_scores.append(np.mean(subscores))

df["New_Composability_Score_raw"] = new_scores


# ------------------------------------------------
# 7. Scale OLD + NEW Scores to 0â€“1
# ------------------------------------------------
def min_max_scale(series):
    return (series - series.min()) / (series.max() - series.min() + 1e-9)

df["Old_Composability_Score"] = min_max_scale(df["Old_Composability_Score_raw"])
df["New_Composability_Score"] = min_max_scale(df["New_Composability_Score_raw"])

# ------------------------------------------------
# 8. Save dataset
# ------------------------------------------------
df.to_csv("dataset_with_scaled_composability_scores.csv", index=False)
print("ðŸŽ‰ Done! Old & New composability scores generated and scaled to [0, 1].")

df = df.dropna().reset_index(drop=True)

df['dataset'].value_counts()

# ---------------------------------------------
# Compute sq(sol) = old_raw / new_raw
# ---------------------------------------------
df["SQ_Composability"] = df["Old_Composability_Score"] / (df["New_Composability_Score"] + 1e-9)

# Optional: also scale solution quality into 0â€“1 if needed
min_sq = df["SQ_Composability"].min()
max_sq = df["SQ_Composability"].max()

df["SQ_Composability_Scaled"] = (df["SQ_Composability"] - min_sq) / (max_sq - min_sq + 1e-9)

# Save again
df.to_csv("dataset_with_sq_scores.csv", index=False)
print("ðŸŽ¯ Solution-quality score (SQ_Composability) computed and saved.")

df.columns

df

df.to_csv("new.csv")

import pandas as pd
import numpy as np
from sklearn.utils import resample

# Load data
df = pd.read_csv("new.csv")

# Choose target sample size strategy
# Option 1: max size
# target_size = df.groupby("dataset").size().max()

# Option 2: min size  (recommended default)
target_size = df.groupby("dataset").size().min()

# Option 3: custom size (uncomment and specify)
# target_size = 400

equalized_dfs = []

for dataset_name, subset in df.groupby("dataset"):
    current_size = len(subset)

    if current_size > target_size:
        # Downsample (without replacement)
        subset_resampled = resample(subset, replace=False, n_samples=target_size, random_state=42)
    else:
        # Upsample (with replacement)
        subset_resampled = resample(subset, replace=True, n_samples=target_size, random_state=42)

    equalized_dfs.append(subset_resampled)

df_equalized = pd.concat(equalized_dfs).reset_index(drop=True)

print("Equalized sample counts per dataset:\n")
print(df_equalized.groupby("dataset").size())

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib

# ==============================
# FONT & ACM DIMENSIONS
# ==============================
matplotlib.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman", "Times", "DejaVu Serif"],
})

label_size = 30
tick_size = 28
legend_size = 22
fig_size = (20.5, 9.5)

# ==============================
# DATA PREPARATION
# ==============================
df = df_equalized.copy()   # <-- ensure df_equalized is already prepared
GROUP_SIZE = 50

df["group_index"] = df.groupby("dataset").cumcount() // GROUP_SIZE

grouped = (
    df.groupby(["group_index", "dataset"])[
        ["SQ_Composability_Scaled", "Old_Composability_Score"]
    ]
    .mean()
    .reset_index()
)

grouped = grouped.sort_values(by=["group_index", "dataset"])

# ==============================
# DATASET NAME MAPPING
# ==============================
rename_map = {
    "digits": "MLaaS Digits",
    "fashion_mnist": "MLaaS Fashion-MNIST",
    "mnist": "MLaaS MNIST"
}
grouped["dataset_label"] = grouped["dataset"].map(rename_map)

# ==============================
# UPDATED COLOR MAP (Blue / Orange / Violet)
# ==============================
color_map = {
    "MLaaS Digits": "#1f77b4",        # Deep Blue
    "MLaaS Fashion-MNIST": "#ff7f0e", # Orange
    "MLaaS MNIST": "#9467bd"          # Violet
}

# ==============================
# PLOT
# ==============================
fig, ax = plt.subplots(figsize=fig_size)

for dataset_label in grouped["dataset_label"].unique():
    subset = grouped[grouped["dataset_label"] == dataset_label]

    if dataset_label == "MLaaS MNIST":
        ax.plot(
            subset["group_index"],
            subset["Old_Composability_Score"],
            linestyle="-", marker="o",
            linewidth=5, markersize=10,
            color=color_map[dataset_label],
            label=f"{dataset_label} â€” New"
        )
        ax.plot(
            subset["group_index"],
            subset["SQ_Composability_Scaled"],
            linestyle="--", marker="x",
            linewidth=5, markersize=10,
            color=color_map[dataset_label],
            label=f"{dataset_label} â€” Old"
        )
    else:
        ax.plot(
            subset["group_index"],
            subset["SQ_Composability_Scaled"],
            linestyle="-", marker="o",
            linewidth=5 ,markersize=10,
            color=color_map[dataset_label],
            label=f"{dataset_label} â€” New"
        )
        ax.plot(
            subset["group_index"],
            subset["Old_Composability_Score"],
            linestyle="--", marker="x",
            linewidth=5, markersize=10,
            color=color_map[dataset_label],
            label=f"{dataset_label} â€” Old"
        )

# ==============================
# LABELS & LEGEND
# ==============================
ax.set_xlabel("Number of Services", fontsize=label_size)
ax.set_ylabel("Average Solution Quality ", fontsize=label_size)

ax.tick_params(axis="x", labelsize=tick_size)
ax.tick_params(axis="y", labelsize=tick_size)

ax.grid(axis='y', linestyle='--', alpha=0.35)
ax.set_axisbelow(True)

legend = ax.legend(
    loc="upper center",
    bbox_to_anchor=(0.52, 1.17),
    ncol=3,
    frameon=True,
    fontsize=legend_size,
    title="",
    title_fontsize=legend_size
)
legend.get_frame().set_alpha(0.92)

ax.set_title("", fontsize=label_size)

fig.tight_layout(rect=[0, 0, 1, 0.94])

# ==============================
# SAVE FIGURE
# ==============================
fig.savefig("mlaas_composability_new_vs_old_acm.png", dpi=400, bbox_inches="tight")
fig.savefig("mlaas_composability_new_vs_old_acm.pdf", bbox_inches="tight")

plt.show()

import numpy as np
import pandas as pd

df = pd.read_csv("filtered dataset.csv")

# ==============================
# Step 1: Global Reference Values
# ==============================
avg_time = df["computation_time"].mean()
avg_quality = df["metric_score"].mean()
avg_volume = df["data_volume"].mean()

# global reference distribution
dist_list = df["data_distribution"].apply(lambda x: np.array(list(eval(x).values())))
global_ref_dist = np.mean(np.vstack(dist_list), axis=0)

# dataset averages for NEW metrics
df["train_eff"] = df["metric_score"] / (df["cpu_time_s"] + 1)
df["comm_eff"]  = df["metric_score"] / (df["comm_bytes_up"] + df["comm_bytes_down"] + 1)
df["mem_eff"]   = df["metric_score"] / (df["memory_used_mb"] + 1)
df["comp_eff"]  = df["metric_score"] / (df["computation_time"] + 1)
df["data_util"] = df["metric_score"] * df["data_volume"]
df["model_norm"] = df["metric_score"] / (df["params_count"] + 1)

avg_train = df["train_eff"].mean()
avg_comm  = df["comm_eff"].mean()
avg_mem   = df["mem_eff"].mean()
avg_comp  = df["comp_eff"].mean()
avg_data  = df["data_util"].mean()
avg_model = df["model_norm"].mean()

# ==============================
# Step 2: Scoring Functions (Old + New)
# ==============================
def S_dist(dist):
    return 1 / (1 + np.linalg.norm(dist - global_ref_dist))

def S_time(t):
    return avg_time / (t + avg_time)

def S_quality(q):
    return 1 / (1 + abs(q - avg_quality))

def S_rel(r):
    return r  # already 0â€“1

def S_volume(v):
    return v / (v + avg_volume)

def norm_score(x, avg):
    return x / (x + avg + 1e-9)

# ==============================
# Step 3: Compute Final Composability Score
# ==============================
scores = []
for idx, row in df.iterrows():
    dist = np.array(list(eval(row["data_distribution"]).values()))

    subscores = [
        S_dist(dist),
        S_time(row["computation_time"]),
        S_quality(row["metric_score"]),
        S_rel(row["global_score"]),
        S_volume(row["data_volume"]),
        norm_score(row["train_eff"], avg_train),
        norm_score(row["comm_eff"], avg_comm),
        norm_score(row["mem_eff"], avg_mem),
        norm_score(row["comp_eff"], avg_comp),
        norm_score(row["data_util"], avg_data),
        norm_score(row["model_norm"], avg_model)
    ]

    scores.append(np.mean(subscores))

df["New_Composability_Score"] = scores

df.to_csv("dataset_with_final_composability_scores.csv", index=False)
print("New composability scores created")

df

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib

# ==============================
# FONT & ACM DIMENSIONS
# ==============================
matplotlib.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman", "Times", "DejaVu Serif"],
})

label_size = 30
tick_size = 33
legend_size = 22
fig_size = (20.5, 9.5)

# ==============================
# DATA PREPARATION
# ==============================
df = df_equalized.copy()   # ensure df_equalized already prepared
GROUP_SIZE = 10

df["group_index"] = df.groupby("dataset").cumcount() // GROUP_SIZE

grouped = (
    df.groupby("group_index")[["SQ_Composability_Scaled", "Old_Composability_Score"]]
      .mean()
      .reset_index()
)

grouped = grouped.sort_values(by=["group_index"])

# ==============================
# PLOT (Two-Line Comparison)
# ==============================
fig, ax = plt.subplots(figsize=fig_size)

# Solid Line â€” Our MLaaS Dataset (New Adaptive Composability)
ax.plot(
    grouped["group_index"],
    grouped["SQ_Composability_Scaled"],
    linestyle="-", marker="o",
    linewidth=5.2, markersize=10,
    color="#1f77b4",
    label="Adaptive Composability â€” Our MLaaS Dataset (New)"
)

# Dashed Line â€” Incomplete MLaaS Dataset (Old Adaptive Composability)
ax.plot(
    grouped["group_index"],
    grouped["Old_Composability_Score"],
    linestyle="--", marker="x",
    linewidth=5.0, markersize=10,
    color="#d62728",
    label="Adaptive Composability â€” Incomplete MLaaS Dataset (Old)"
)

# ==============================
# LABELS & LEGEND
# ==============================
ax.set_xlabel("Number of Services", fontsize=label_size)
ax.set_ylabel("Average Solution Quality", fontsize=label_size)

ax.tick_params(axis="x", labelsize=tick_size)
ax.tick_params(axis="y", labelsize=tick_size)

ax.grid(axis='y', linestyle='--', alpha=0.35)
ax.set_axisbelow(True)

legend = ax.legend(
    loc="upper center",
    bbox_to_anchor=(0.52, 1.15),
    ncol=2,
    frameon=True,
    fontsize=legend_size
)
legend.get_frame().set_alpha(0.92)

ax.set_title("", fontsize=label_size)

fig.tight_layout(rect=[0, 0, 1, 0.90])

# ==============================
# SAVE FIGURE
# ==============================
fig.savefig("adaptive_composability_ours_vs_incomplete.png", dpi=400, bbox_inches="tight")
fig.savefig("adaptive_composability_ours_vs_incomplete.pdf", bbox_inches="tight")

plt.show()

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import matplotlib

# ==============================
# FONT & ACM DIMENSIONS
# ==============================
matplotlib.rcParams.update({
    "font.family": "serif",
    "font.serif": ["Times New Roman", "Times", "DejaVu Serif"],
})

label_size = 30
tick_size = 26
legend_size = 18
fig_size = (21.5, 9.5)

# ==============================
# DATA PREPARATION
# ==============================
df = df_equalized.copy()   # ensure this contains our dataset composability scores
GROUP_SIZE = 10

df["group_index"] = df.groupby("dataset").cumcount() // GROUP_SIZE

grouped = (
    df.groupby("group_index")[["SQ_Composability_Scaled", "Old_Composability_Score"]]
    .mean()
    .reset_index()
)

# ==============================
# PLOT â€” Two-Line Comparison
# ==============================
fig, ax = plt.subplots(figsize=fig_size)

# Our Adaptive Composability (New scoring)
ax.plot(
    grouped["group_index"],
    grouped["SQ_Composability_Scaled"],
    linestyle="-", marker="o",
    linewidth=3.2, markersize=10,
    color="#1f77b4",
    label="Adaptive Composability â€” Our MLaaS Dataset (New)"
)

# Incomplete MLaaS Dataset (Old scoring)
ax.plot(
    grouped["group_index"],
    grouped["Old_Composability_Score"],
    linestyle="--", marker="x",
    linewidth=3.0, markersize=10,
    color="#d62728",
    label="Adaptive Composability â€” Incomplete MLaaS Dataset (Old)"
)

# ==============================
# LABELS, GRID, LEGEND
# ==============================
ax.set_xlabel("Number of Services (100-sample groups)", fontsize=label_size)
ax.set_ylabel("Average Solution Quality", fontsize=label_size)

ax.tick_params(axis="x", labelsize=tick_size)
ax.tick_params(axis="y", labelsize=tick_size)

ax.grid(axis="y", linestyle="--", alpha=0.35)
ax.set_axisbelow(True)

legend = ax.legend(
    loc="upper center",
    bbox_to_anchor=(0.5, 1.13),
    ncol=1,
    frameon=True,
    fontsize=legend_size,
    title="",
    title_fontsize=legend_size
)
legend.get_frame().set_alpha(0.92)

ax.set_title("", fontsize=label_size)

fig.tight_layout(rect=[0, 0, 1, 0.93])

# ==============================
# SAVE FIGURE
# ==============================
fig.savefig("adaptive_composability_two_dataset_comparison.png", dpi=400, bbox_inches="tight")
fig.savefig("adaptive_composability_two_dataset_comparison.pdf", bbox_inches="tight")

plt.show()