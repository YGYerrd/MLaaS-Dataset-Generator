# Machine Learning as a Service (MLaaS) Dataset Generator
Framework for IoT Environments

We propose a novel MLaaS Dataset Generator (MDG) framework
that creates configurable and reproducible datasets for evaluating
Machine Learning as a Service (MLaaS) selection and composition.
MDG simulates realistic MLaaS behaviour by training and evaluat-
ing diverse model families across multiple real-world datasets and
data distribution settings. It records detailed functional attributes,
quality of service metrics, and composition-specific indicators, en-
abling systematic analysis of service performance and cross-service
behaviour. Using MDG, we generate more than ten thousand MLaaS
service instances and construct a large-scale benchmark dataset
suitable for downstream evaluation. We also implement a built-in
composition mechanism that models how services interact under
varied Internet of Things conditions. Experiments demonstrate
that datasets generated by MDG enhance selection accuracy and
composition quality compared to existing baselines. MDG provides
a practical and extensible foundation for advancing data-driven
research on MLaaS selection and composition

## Overview

The **MLaaS Dataset Generator (MDG)** is a framework for generating large-scale, configurable, and reproducible datasets to support research on **Machine Learning as a Service (MLaaS) selection and composition**.

MDG simulates realistic MLaaS behaviour by training and evaluating heterogeneous machine-learning models under a lightweight **federated learning** loop. Each simulated service instance corresponds to a client trained under specific data distributions, hyperparameters, and participation settings. The framework records detailed functional attributes and quality-of-service (QoS) metrics, enabling systematic analysis of service performance and cross-service interactions.

Using MDG, **tens of thousands of synthetic MLaaS service instances** are able to be generated, producing benchmark datasets suitable for downstream evaluation tasks such as:
- MLaaS service selection
- Service composition
- Reliability and performance analysis
- Behaviour under heterogeneous IoT data distributions

The framework is designed to be **extensible**, **reproducible**, and **dataset-agnostic**, providing a practical foundation for data-driven MLaaS research.

---

## Key Features

- Lightweight federated learning simulation  
- Multiple real-world datasets (MNIST, Fashion-MNIST)  
- IID and non-IID data distribution strategies  
- Configurable model architectures and training hyperparameters  
- Per-round, per-client metric recording  
- CSV-based outputs suitable for large-scale analytics  
- Built-in dataset merging and de-duplication utilities  

---

## Conceptual Model

Each run of the generator simulates a population of MLaaS providers:

- Each **client** represents an individual MLaaS service  
- Each **round** represents a composition of MLaaS services  
- Clients train local models on heterogeneous data partitions  
- A global aggregation step produces shared model updates  
- Metrics are recorded for every client in every round  

During execution, all generated records are **automatically written to a default SQL database backend**, enabling incremental storage, structured querying, and scalable downstream analysis. CSV files produced by the CLI are exported views derived from this underlying database.

The resulting dataset captures both **individual service behaviour** and **cross-service dynamics**.

---

## Installation

Clone the repository and install dependencies:

```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
pip install -r requirements.txt
```

Python 3.11 is recommended.

---

## Command-Line Interface

MDG is accessed via a unified command-line interface:

```bash
python -m mlaas_data_generator.cli <subcommand> [options]
```

### Subcommands

- `generate` — run the federated simulation and write a per-round, per-client CSV  
- `merge` — combine multiple CSV outputs into a single dataset  
- `wizard` — interactive configuration helper  

---

## Usage

### Wizard (recommended for first use)

```bash
python -m mlaas_data_generator.cli wizard
```

---

### Minimal Run (IID)

```bash
python -m mlaas_data_generator.cli generate \
  --clients 5 \
  --dataset fashion_mnist \
  --strategy iid \
  --output clients.csv
```

---

## Data Distribution Strategies

The `--strategy` flag controls how data is partitioned across clients.

| Strategy | Description |
|--------|-------------|
| `iid` | Independent and identically distributed data |
| `quantity_skew` | Dirichlet α over client data sizes (higher α → more even) |
| `dirichlet` | Dirichlet α over label distributions per client |
| `shard` | Label-sorted shards randomly assigned to clients |
| `label_per_client` | Fixed number of labels per client |
| `custom` | User-defined per-client label counts (JSON) |

---

### Quantity Skew

```bash
python -m mlaas_data_generator.cli generate \
  --clients 5 \
  --strategy quantity_skew \
  --distribution-param 0.3 \
  --output qskew.csv
```

---

### Dirichlet Label Skew

```bash
python -m mlaas_data_generator.cli generate \
  --clients 10 \
  --strategy dirichlet \
  --distribution-param 0.2 \
  --output dirichlet.csv
```

---

### Shard-based Partitioning

```bash
python -m mlaas_data_generator.cli generate \
  --clients 5 \
  --strategy shard \
  --distribution-param 2 \
  --output shard.csv
```

---

### Fixed Labels per Client

```bash
python -m mlaas_data_generator.cli generate \
  --clients 5 \
  --strategy label_per_client \
  --distribution-param 2 \
  --output klabels.csv
```

---

### Custom Distributions

```bash
python -m mlaas_data_generator.cli generate \
  --clients 5 \
  --strategy custom \
  --distribution custom_distributions.json \
  --output custom.csv
```

---

## Dataset Downsampling

Optional downsampling can be applied **before** data partitioning:

```bash
# Fixed number of samples
--sample-size 30000

# Fraction of the dataset
--sample-frac 0.5
```

---

## Model Configuration

Model architecture and training parameters are fully configurable:

```bash
python -m mlaas_data_generator.cli generate \
  --clients 10 \
  --dataset mnist \
  --strategy quantity_skew \
  --distribution-param 0.5 \
  --hidden-layers "128,64,32" \
  --activation relu \
  --dropout 0.3 \
  --weight-decay 1e-4 \
  --optimizer adamw \
  --epochs-per-round 3 \
  --batch-size 64 \
  --learning-rate 0.001 \
  --output run_deep.csv
```

---

## Output

Each `generate` run produces a CSV file containing:

- Client ID  
- Round number  
- Dataset and distribution metadata  
- Model hyperparameters  
- Training and evaluation metrics  
- Reliability indicators  

Outputs are written under:

```
outputs/runs/
```

---

## Reproducibility

All experiments are fully parameterised via the CLI. Re-running a command with the same configuration yields identical dataset schemas and comparable metrics, enabling controlled experimental evaluation.

---
