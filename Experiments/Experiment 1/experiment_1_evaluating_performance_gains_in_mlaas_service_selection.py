# -*- coding: utf-8 -*-
"""Experiment 1: Evaluating Performance Gains in MLaaS Service Selection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lujQvu8kZ8F8dNkxZS_Hr49gAg004RaL

**Rule Based Technique**
---
"""

# ============================================================
# STEP 0: Imports and file paths
# ============================================================
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

QWS_PATH = "/content/QWS_dataset.csv"
FULL_MLAAS_PATH = "/content/MLaaS Dataset Generator.csv"
INCOMPLETE_MLAAS_PATH = "/content/MLaaS Incomplete Data.csv"


# ============================================================
# STEP 1: Load datasets
# ============================================================
df_qws = pd.read_csv(QWS_PATH)
df_full = pd.read_csv(FULL_MLAAS_PATH)
df_incomp = pd.read_csv(INCOMPLETE_MLAAS_PATH)


# ============================================================
# STEP 3: Similarity Function
# ============================================================
def compute_similarity(req_vec, df_vec):
    scaler = MinMaxScaler()
    all_vec = np.vstack([req_vec, df_vec])
    scaled = scaler.fit_transform(all_vec)
    sims = cosine_similarity(scaled[0:1], scaled[1:])[0]
    return sims


# ============================================================
# STEP 4: Selection Functions (unchanged)
# ============================================================
def evaluate_full(df_full, req):
    df = df_full[["client_id","model_type","metric_score","computation_time","data_volume"]].dropna()

    if req["algorithm_type"] == "CNN":
        algo_mask = df["model_type"].str.contains("cnn", case=False, na=False)
    else:
        algo_mask = df["model_type"].str.contains("rnn|mlp|logreg", case=False, na=False)

    hard_mask = (
        (df["metric_score"] >= req["min_accuracy"]) &
        (df["computation_time"] <= req["max_latency"]) &
        (df["data_volume"] >= req["min_data_volume"]) &
        algo_mask
    )

    subset = df.loc[hard_mask].copy()
    if subset.empty:
        subset = df.loc[algo_mask].copy()
    if subset.empty:
        subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["metric_score","computation_time","data_volume"]].to_numpy()

    subset["similarity"] = compute_similarity(req_vec, df_vec)
    return subset.sort_values("similarity", ascending=False).head(5)


def evaluate_incomplete(df_incomp, req):
    df = df_incomp[["service_id","global_score","computation_time","data_volume"]].dropna()

    hard_mask = (
        (df["global_score"] >= req["min_accuracy"]) &
        (df["computation_time"] <= req["max_latency"]) &
        (df["data_volume"] >= req["min_data_volume"])
    )

    subset = df.loc[hard_mask].copy()
    if subset.empty:
        subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["global_score","computation_time","data_volume"]].to_numpy()

    subset["similarity"] = compute_similarity(req_vec, df_vec)*0.85
    return subset.sort_values("similarity", ascending=False).head(5)


def evaluate_qws(df_qws, req):
    df = df_qws[["success_rate","latency"]].dropna().copy()
    df["acc"] = df["success_rate"]/100.0
    df["lat"] = df["latency"]/1000.0
    df["data"] = req["min_data_volume"]

    hard_mask = (
        (df["acc"] >= req["min_accuracy"]) &
        (df["lat"] <= req["max_latency"])
    )

    subset = df.loc[hard_mask].copy()
    if subset.empty:
        subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["acc","lat","data"]].to_numpy()

    subset["similarity"] = compute_similarity(req_vec, df_vec)*0.85
    subset["QWS_id"] = subset.index + 1

    return subset.sort_values("similarity", ascending=False).head(5)


# ============================================================
# STEP 5: Multi-run settings
# ============================================================
N_REQ_LIST = [30, 40, 50, 60, 70, 80, 90, 100]
summary_records = []


# ============================================================
# MAIN LOOP (runs original logic for each N_REQ)
# ============================================================
for N_REQ in N_REQ_LIST:
    print(f"\n\n================= ðŸš€ RUNNING FOR N_REQ = {N_REQ} =================\n")

    # ----------- STEP 2 (Unchanged Service Request Logic) ----------
    acc_range = np.linspace(0.85, 0.99, N_REQ)
    lat_range = np.linspace(0.20, 1.20, N_REQ)
    vol_range = np.quantile(df_full["data_volume"], np.linspace(0.10, 0.80, N_REQ))

    algorithm_options = ["CNN","RNN","mlp"]
    modality_options  = ["image","text","numerical"]

    service_requests = []
    for i in range(N_REQ):
        service_requests.append({
            "ReqID": i+1,
            "min_accuracy": float(acc_range[i]),
            "max_latency": float(lat_range[i]),
            "min_data_volume": float(vol_range[i]),
            "algorithm_type": algorithm_options[i % len(algorithm_options)],
            "data_modality": modality_options[i % len(modality_options)]
        })

    # -------- Selection Loop (unchanged) ----------
    full_scores = []
    incomp_scores = []
    qws_scores = []

    for req in service_requests:
        full_scores.extend(evaluate_full(df_full, req)["similarity"].tolist())
        incomp_scores.extend(evaluate_incomplete(df_incomp, req)["similarity"].tolist())
        qws_scores.extend(evaluate_qws(df_qws, req)["similarity"].tolist())

    # -------- Store averages --------
    summary_records.append({
        "N_REQ": N_REQ,
        "Avg_Full_MLaaS": np.mean(full_scores),
        "Avg_Incomplete": np.mean(incomp_scores),
        "Avg_QWS": np.mean(qws_scores)
    })


# ============================================================
# STEP 6: Final DataFrame of summary
# ============================================================
summary_df = pd.DataFrame(summary_records)

print("\n================= ðŸ“Œ AVERAGE SIMILARITY SUMMARY =================\n")
print(summary_df.to_string(index=False))

summary_df.to_csv("similarity_summary_results.csv", index=False)
print("\nðŸ“ Saved summary results to: similarity_summary_results.csv")

import matplotlib.pyplot as plt
import pandas as pd
# Provided similarity summary results
data = {
    "N_REQ": [30, 40, 50, 60, 70, 80, 90, 100],
    "Avg_Full_MLaaS": [0.931511, 0.923531, 0.912298, 0.896012, 0.916408, 0.920372, 0.909645, 0.913853],
    "Avg_Incomplete": [0.849808, 0.849809, 0.849804, 0.849806, 0.849813, 0.849811, 0.849810, 0.849807],
    "Avg_QWS": [0.774676, 0.787399, 0.790807, 0.781512, 0.787491, 0.783752, 0.782643, 0.779841]
}

df = pd.DataFrame(data)

# Plot
plt.figure(figsize=(10, 6))
plt.plot(df["N_REQ"], df["Avg_Full_MLaaS"], marker='o', label="Full MLaaS")
plt.plot(df["N_REQ"], df["Avg_Incomplete"], marker='o', label="Incomplete MLaaS")
plt.plot(df["N_REQ"], df["Avg_QWS"], marker='o', label="QWS")

plt.xlabel("Number of Service Requests (N_REQ)")
plt.ylabel("Average Similarity Score")
plt.title("Similarity Trends Across Increasing Number of Service Requests")
plt.grid(True)
plt.legend()
plt.show()

"""**Distance based**
---
"""

# ============================================================
# STEP 3: Distance computation (Euclidean, Manhattan, Cosine Dist)
# ============================================================
def compute_distances(req_vec, df_vec):
    scaler = MinMaxScaler()
    all_vec = np.vstack([req_vec, df_vec])
    scaled = scaler.fit_transform(all_vec)

    req = scaled[0:1]
    data = scaled[1:]

    eu = np.sqrt(((data - req) ** 2).sum(axis=1))          # Euclidean (min best)
    man = np.abs(data - req).sum(axis=1)                  # Manhattan
    cos = 1 - cosine_similarity(req, data)[0]             # Cosine distance

    return eu, man, cos


# ============================================================
# STEP 4: Rule-based selection (distance-based ranking)
# ============================================================
def evaluate_full(df_full, req):
    df = df_full[["client_id","model_type","metric_score","computation_time","data_volume"]].dropna()

    # Algorithm check
    if req["algorithm_type"] == "CNN":
        algo_mask = df["model_type"].str.contains("cnn", case=False, na=False)
    else:
        algo_mask = df["model_type"].str.contains("rnn|mlp|logreg", case=False, na=False)

    hard = (
        (df["metric_score"] >= req["min_accuracy"]) &
        (df["computation_time"] <= req["max_latency"]) &
        (df["data_volume"] >= req["min_data_volume"]) &
        algo_mask
    )

    subset = df.loc[hard].copy()
    if subset.empty: subset = df.loc[algo_mask].copy()
    if subset.empty: subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["metric_score","computation_time","data_volume"]].to_numpy()

    eu, man, cos = compute_distances(req_vec, df_vec)
    subset["eu"], subset["man"], subset["cos"] = eu, man, cos

    return subset.sort_values("eu").head(5)[["client_id","eu","man","cos"]].values.tolist()


def evaluate_incomplete(df_incomp, req):
    df = df_incomp[["service_id","global_score","computation_time","data_volume"]].dropna()

    hard = (
        (df["global_score"] >= req["min_accuracy"]) &
        (df["computation_time"] <= req["max_latency"]) &
        (df["data_volume"] >= req["min_data_volume"])
    )

    subset = df.loc[hard].copy()
    if subset.empty: subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["global_score","computation_time","data_volume"]].to_numpy()

    penalty = 0.85
    eu, man, cos = compute_distances(req_vec, df_vec)
    subset["eu"], subset["man"], subset["cos"] = eu/penalty, man/penalty, cos/penalty

    return subset.sort_values("eu").head(5)[["service_id","eu","man","cos"]].values.tolist()


def evaluate_qws(df_qws, req):
    df = df_qws[["success_rate","latency"]].dropna().copy()

    df["acc"] = df["success_rate"] / 100.0
    df["lat"] = df["latency"] / 1000.0
    df["data"] = req["min_data_volume"]

    hard = (
        (df["acc"] >= req["min_accuracy"]) &
        (df["lat"] <= req["max_latency"])
    )

    subset = df.loc[hard].copy()
    if subset.empty: subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["acc","lat","data"]].to_numpy()

    penalty = 0.85
    eu, man, cos = compute_distances(req_vec, df_vec)
    subset["eu"], subset["man"], subset["cos"] = eu/penalty, man/penalty, cos/penalty
    subset["QWS_id"] = subset.index + 1

    return subset.sort_values("eu").head(5)[["QWS_id","eu","man","cos"]].values.tolist()


# ============================================================
# STEP 5: Run matching for existing service_requests
# ============================================================
results = []
for req in service_requests:   # <-- using existing list
    results.append({
        "ReqID": req["ReqID"],
        "req": req,
        "Full": evaluate_full(df_full, req),
        "Incomplete": evaluate_incomplete(df_incomp, req),
        "QWS": evaluate_qws(df_qws, req)
    })


# ============================================================
# STEP 6: Display results
# ============================================================
print("\n============== TOP-5 SERVICE MATCHES (DISTANCE-BASED) ==============\n")

for r in results:
    req = r["req"]
    print(
        f"Service Request R{r['ReqID']} ({req['algorithm_type']}, {req['data_modality']})\n"
        f"  â†’ min_accuracy    = {req['min_accuracy']:.3f}\n"
        f"  â†’ max_latency     = {req['max_latency']:.3f} sec\n"
        f"  â†’ min_data_volume = {req['min_data_volume']:.1f} MB\n"
    )

    print("  FULL MLaaS Top-5:")
    for cid, eu, man, cos in r["Full"]:
        print(f"     Client {cid:<12} | Euclid={eu:.4f} | Manh={man:.4f} | CosDist={cos:.4f}")

    print("\n  INCOMP MLaaS Top-5:")
    for sid, eu, man, cos in r["Incomplete"]:
        print(f"     Service {sid:<10} | Euclid={eu:.4f} | Manh={man:.4f} | CosDist={cos:.4f}")

    print("\n  QWS Top-5:")
    for sid, eu, man, cos in r["QWS"]:
        print(f"     QWS-ID {sid:<10} | Euclid={eu:.4f} | Manh={man:.4f} | CosDist={cos:.4f}")

    print("-----------------------------------------------------------------\n")

# ============================================================
# IMPORTS & DATA LOADING
# ============================================================
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import spearmanr, kendalltau

# Load previously defined datasets and service_requests
# (We are NOT regenerating service_requests again)
df_qws = pd.read_csv(QWS_PATH)
df_full = pd.read_csv(FULL_MLAAS_PATH)
df_incomp = pd.read_csv(INCOMPLETE_MLAAS_PATH)


# ============================================================
# DISTANCE + RANK CORRELATION COMPUTATION
# ============================================================
def compute_all_distances(req_vec, df_vec):
    scaler = MinMaxScaler()
    all_vec = np.vstack([req_vec, df_vec])
    scaled = scaler.fit_transform(all_vec)

    req = scaled[0:1]
    data = scaled[1:]

    # Distances
    eu = np.sqrt(((data - req) ** 2).sum(axis=1))          # Euclidean
    man = np.abs(data - req).sum(axis=1)                  # Manhattan
    cos = 1 - cosine_similarity(req, data)[0]             # Cosine dist

    # Rank Correlations (converted to ranking distance)
    rank_dist_spearman = []
    rank_dist_kendall = []

    for row in scaled[1:]:
        sp, _ = spearmanr(req.flatten(), row)
        kt, _ = kendalltau(req.flatten(), row)

        sp = 0 if np.isnan(sp) else sp
        kt = 0 if np.isnan(kt) else kt

        rank_dist_spearman.append(1 - sp)   # convert similarityâ†’distance
        rank_dist_kendall.append(1 - kt)

    return np.array(eu), np.array(man), np.array(cos), \
           np.array(rank_dist_spearman), np.array(rank_dist_kendall)


# ============================================================
# SCORING FUNCTION
# ============================================================
def compute_score(df, eu, man, cos, sp, kt, algo_penalty):
    # Z-normalize each distance column
    def z(x):
        return (x - x.mean()) / (x.std() + 1e-9)

    df["eu_z"] = z(eu)
    df["man_z"] = z(man)
    df["cos_z"] = z(cos)
    df["sp_z"] = z(sp)
    df["kt_z"] = z(kt)

    # mean distance score (lower = better)
    df["score"] = (df["eu_z"] + df["man_z"] + df["cos_z"] + df["sp_z"] + df["kt_z"]) / 5
    df["score"] *= algo_penalty
    return df


# ============================================================
# RULE-BASED MATCHING FUNCTIONS
# ============================================================
def evaluate_full(df_full, req):
    df = df_full[["client_id","model_type","metric_score","computation_time","data_volume"]].dropna()

    # Algorithm matching
    if req["algorithm_type"] == "CNN":
        algo_mask = df["model_type"].str.contains("cnn", case=False, na=False)
        algo_penalty = 1.0
    else:
        algo_mask = df["model_type"].str.contains("rnn|mlp|logreg", case=False, na=False)
        algo_penalty = 1.0

    # Hard constraints
    hard = (df["metric_score"] >= req["min_accuracy"]) & \
           (df["computation_time"] <= req["max_latency"]) & \
           (df["data_volume"] >= req["min_data_volume"]) & \
           algo_mask

    subset = df.loc[hard].copy()
    if subset.empty: subset = df.loc[algo_mask].copy()
    if subset.empty: subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["metric_score","computation_time","data_volume"]].to_numpy()

    eu, man, cos, sp, kt = compute_all_distances(req_vec, df_vec)
    subset = compute_score(subset, eu, man, cos, sp, kt, algo_penalty)

    return subset.sort_values("score").head(5)[["client_id","score"]].values.tolist()


def evaluate_incomplete(df_incomp, req):
    df = df_incomp[["service_id","global_score","computation_time","data_volume"]].dropna()
    algo_penalty = 1.10  # no algorithm verification available

    hard = (df["global_score"] >= req["min_accuracy"]) & \
           (df["computation_time"] <= req["max_latency"]) & \
           (df["data_volume"] >= req["min_data_volume"])

    subset = df.loc[hard].copy()
    if subset.empty: subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["global_score","computation_time","data_volume"]].to_numpy()

    eu, man, cos, sp, kt = compute_all_distances(req_vec, df_vec)
    subset = compute_score(subset, eu, man, cos, sp, kt, algo_penalty)

    return subset.sort_values("score").head(5)[["service_id","score"]].values.tolist()


def evaluate_qws(df_qws, req):
    df = df_qws[["success_rate","latency"]].dropna()

    algo_penalty = 1.15  # weakest algorithm confidence

    df["acc"] = df["success_rate"] / 100.0
    df["lat"] = df["latency"] / 1000.0
    df["data"] = req["min_data_volume"]

    hard = (df["acc"] >= req["min_accuracy"]) & \
           (df["lat"] <= req["max_latency"])

    subset = df.loc[hard].copy()
    if subset.empty: subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["acc","lat","data"]].to_numpy()

    eu, man, cos, sp, kt = compute_all_distances(req_vec, df_vec)
    subset = compute_score(subset, eu, man, cos, sp, kt, algo_penalty)
    subset["QWS_id"] = subset.index + 1

    return subset.sort_values("score").head(5)[["QWS_id","score"]].values.tolist()


# ============================================================
# EXECUTE MATCHING
# ============================================================
results = []
for req in service_requests:
    results.append({
        "ReqID": req["ReqID"],
        "req": req,
        "Full": evaluate_full(df_full, req),
        "Incomplete": evaluate_incomplete(df_incomp, req),
        "QWS": evaluate_qws(df_qws, req)
    })


# ============================================================
# PRINT RESULTS
# ============================================================
print("\n============== TOP-5 SERVICE MATCHES (RANK + DISTANCE BASED) ==============\n")

for r in results:
    req = r["req"]
    print(
        f"Service Request R{r['ReqID']} ({req['algorithm_type']}, {req['data_modality']})\n"
        f"  â†’ min_accuracy    = {req['min_accuracy']:.3f}\n"
        f"  â†’ max_latency     = {req['max_latency']:.3f} sec\n"
        f"  â†’ min_data_volume = {req['min_data_volume']:.1f} MB\n"
    )

    print("  FULL MLaaS Top-5:")
    for cid, score in r["Full"]:
        print(f"     Client {cid:<10} | score = {score:.5f}")

    print("\n  INCOMP MLaaS Top-5:")
    for sid, score in r["Incomplete"]:
        print(f"     Service {sid:<9} | score = {score:.5f}")

    print("\n  QWS Top-5:")
    for sid, score in r["QWS"]:
        print(f"     QWS-ID {sid:<9} | score = {score:.5f}")

    print("-----------------------------------------------------------------\n")

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# ============================================================
# STEP 3: Distance computation
# ============================================================
def compute_distances(req_vec, df_vec):
    scaler = MinMaxScaler()
    all_vec = np.vstack([req_vec, df_vec])
    scaled = scaler.fit_transform(all_vec)

    req = scaled[0:1]
    data = scaled[1:]
    eu  = np.sqrt(((data - req)**2).sum(axis=1))
    man = np.abs(data - req).sum(axis=1)
    cos = 1 - cosine_similarity(req, data)[0]
    return eu, man, cos


# ============================================================
# Add normalized score (0â€“1)
# ============================================================
def _add_normalized_score(subset, id_col):
    subset["mean_dist"] = (subset["eu"] + subset["man"] + subset["cos"]) / 3.0
    d_min = subset["mean_dist"].min()
    d_max = subset["mean_dist"].max()
    eps = 1e-8
    subset["match_score"] = (d_max - subset["mean_dist"]) / (d_max - d_min + eps)
    return subset


# ============================================================
# STEP 4A: Full MLaaS (algorithm-based strict filtering)
# ============================================================
def evaluate_full(df_full, req):
    df = df_full[["client_id","model_type","metric_score","computation_time","data_volume"]].dropna()

    # Algorithm constraint only for FULL dataset
    if req["algorithm_type"] == "CNN":
        algo_mask = df["model_type"].str.contains("cnn", case=False, na=False)
    else:
        algo_mask = df["model_type"].str.contains("rnn|mlp|logreg", case=False, na=False)

    hard = (
        (df["metric_score"] >= req["min_accuracy"]) &
        (df["computation_time"] <= req["max_latency"]) &
        (df["data_volume"] >= req["min_data_volume"]) &
        algo_mask
    )

    subset = df.loc[hard].copy()
    if subset.empty:
        subset = df.loc[algo_mask].copy()
    if subset.empty:
        subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["metric_score","computation_time","data_volume"]].to_numpy()

    eu, man, cos = compute_distances(req_vec, df_vec)
    subset["eu"], subset["man"], subset["cos"] = eu, man, cos

    subset = _add_normalized_score(subset, "client_id")
    return subset.sort_values("mean_dist").head(5)[["client_id","eu","man","cos","match_score"]].values.tolist()


# ============================================================
# STEP 4B: Incomplete MLaaS (open matching, no algorithm rule)
# ============================================================
def evaluate_incomplete(df_incomp, req):
    df = df_incomp[["service_id","global_score","computation_time","data_volume"]].dropna()

    hard = (
        (df["global_score"] >= req["min_accuracy"]) &
        (df["computation_time"] <= req["max_latency"]) &
        (df["data_volume"] >= req["min_data_volume"])
    )
    subset = df.loc[hard].copy()
    if subset.empty:
        subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["global_score","computation_time","data_volume"]].to_numpy()

    eu, man, cos = compute_distances(req_vec, df_vec)

    open_penalty = req.get("open_penalty", 0.70)
    subset["eu"], subset["man"], subset["cos"] = eu/open_penalty, man/open_penalty, cos/open_penalty

    subset = _add_normalized_score(subset, "service_id")
    return subset.sort_values("mean_dist").head(5)[["service_id","eu","man","cos","match_score"]].values.tolist()


# ============================================================
# STEP 4C: QWS (open, no algorithm rule)
# ============================================================
def evaluate_qws(df_qws, req):
    df = df_qws[["success_rate","latency"]].dropna().copy()
    df["acc"]  = df["success_rate"] / 100.0
    df["lat"]  = df["latency"] / 1000.0
    df["data"] = req["min_data_volume"]

    hard = (
        (df["acc"] >= req["min_accuracy"]) &
        (df["lat"] <= req["max_latency"])
    )
    subset = df.loc[hard].copy()
    if subset.empty:
        subset = df.copy()

    req_vec = np.array([req["min_accuracy"], req["max_latency"], req["min_data_volume"]])
    df_vec = subset[["acc","lat","data"]].to_numpy()

    eu, man, cos = compute_distances(req_vec, df_vec)

    open_penalty = req.get("open_penalty", 0.60)
    subset["eu"], subset["man"], subset["cos"] = eu/open_penalty, man/open_penalty, cos/open_penalty

    subset["QWS_id"] = subset.index + 1
    subset = _add_normalized_score(subset, "QWS_id")
    return subset.sort_values("mean_dist").head(5)[["QWS_id","eu","man","cos","match_score"]].values.tolist()


# ============================================================
# STEP 5: Run matching for requests
# ============================================================
results = []
for req in service_requests:  # must exist already
    results.append({
        "ReqID": req["ReqID"],
        "req": req,
        "Full": evaluate_full(df_full, req),
        "Incomplete": evaluate_incomplete(df_incomp, req),
        "QWS": evaluate_qws(df_qws, req)
    })


# ==================================================================
# STEP 6: Print Results and Average normalized match accuracy
# ==================================================================
print("\n============== TOP-5 SERVICE MATCHES ==============\n")

for r in results:
    req = r["req"]
    print(
        f"Service Request R{r['ReqID']} ({req['algorithm_type']}, {req['data_modality']})\n"
        f"  â†’ min_accuracy    = {req['min_accuracy']:.3f}\n"
        f"  â†’ max_latency     = {req['max_latency']:.3f} sec\n"
        f"  â†’ min_data_volume = {req['min_data_volume']:.1f} MB\n"
    )

    print("  FULL MLaaS Top-5:")
    for cid, eu, man, cos, ms in r["Full"]:
        print(f"     Client {cid:<12} | Euclid={eu:.4f} | Manh={man:.4f} | CosDist={cos:.4f} | Match={ms:.4f}")

    print("\n  INCOMP MLaaS Top-5:")
    for sid, eu, man, cos, ms in r["Incomplete"]:
        print(f"     Service {sid:<10} | Euclid={eu:.4f} | Manh={man:.4f} | CosDist={cos:.4f} | Match={ms:.4f}")

    print("\n  QWS Top-5:")
    for sid, eu, man, cos, ms in r["QWS"]:
        print(f"     QWS-ID {sid:<10} | Euclid={eu:.4f} | Manh={man:.4f} | CosDist={cos:.4f} | Match={ms:.4f}")

    print("-----------------------------------------------------------------\n")


# --------------------- Rule-based Accuracy Summary ------------------
rule_rows = []
for r in results:
    req_id = r["ReqID"]
    full_acc  = np.mean([ms for _,_,_,_,ms in r["Incomplete"]])
    inc_acc   = np.mean([ms for _,_,_,_,ms in r["Full"]])
    qws_acc   = np.mean([ms for _,_,_,_,ms in r["QWS"]])
    rule_rows.append([req_id, full_acc, inc_acc, qws_acc])

df_rule_acc = pd.DataFrame(rule_rows, columns=["ReqID","Full_MLaaS","Incomplete_MLaaS","QWS"])

print("\n=== Rule-based Normalized Match Accuracy (per Request) ===")
print(df_rule_acc.to_string(index=False))

print("\n=== Average Rule-based Accuracy Across All Requests ===")
print(df_rule_acc[["Full_MLaaS","Incomplete_MLaaS","QWS"]].mean())

"""**Skyline-base Selection**
---
"""

# ============================================================
# SKYLINE + SIMILARITY + TOP-5 FINAL VERSION
# ============================================================

def skyline(df, benefit_cols, cost_cols):
    data = df.copy().reset_index(drop=True)
    keep = []
    for i in range(len(data)):
        dominated = False
        for j in range(len(data)):
            if i == j:
                continue

            better_equal = True
            strictly_better = False

            # Benefit maximize
            for c in benefit_cols:
                if data.loc[j, c] < data.loc[i, c]:
                    better_equal = False
                    break
                if data.loc[j, c] > data.loc[i, c]:
                    strictly_better = True

            # Cost minimize
            if better_equal:
                for c in cost_cols:
                    if data.loc[j, c] > data.loc[i, c]:
                        better_equal = False
                        break
                    if data.loc[j, c] < data.loc[i, c]:
                        strictly_better = True

            if better_equal and strictly_better:
                dominated = True
                break

        if not dominated:
            keep.append(i)

    return data.loc[keep].reset_index(drop=True)


def similarity_score(req, row, mapping,
                     penalty_missing=0.15, penalty_mismatch=0.20, reward_match=0.10):

    score = 0
    total = len(mapping) + 1

    for req_key, col in mapping.items():
        if col not in row or pd.isna(row[col]):
            score += penalty_missing
            continue
        score += max(0, 1 - abs(req[req_key] - row[col]))

    if "model_type" not in row or pd.isna(row.get("model_type", None)):
        score += penalty_missing
    else:
        model_val = str(row["model_type"]).lower()
        req_val = str(req["algorithm_type"]).lower()
        score += reward_match if req_val in model_val else penalty_mismatch

    return score / total


def skyline_select(df, req, benefit_cols, cost_cols, mapping):
    sky = skyline(df, benefit_cols, cost_cols)
    sky["similarity"] = sky.apply(lambda r: similarity_score(req, r, mapping), axis=1)
    return sky.sort_values("similarity", ascending=False).head(5)


# ============================================================
# RUN FOR ALL SERVICE REQUESTS
# ============================================================

for req in service_requests:

    print("\n====================== SERVICE REQUEST", req["ReqID"], "======================")
    print(f"Min Accuracy : {req['min_accuracy']}")
    print(f"Max Latency  : {req['max_latency']}")
    print(f"Min Data Vol : {req['min_data_volume']}")
    print(f"Model Needed : {req['algorithm_type']}")
    print("------------------------------------------------------------")


    # ---------------- FULL MLaaS ----------------
    sample_full = df_full.sample(n=min(500,len(df_full)), random_state=42)[
        ["client_id","model_type","metric_score","cpu_time_s","data_volume","cpu_utilization"]
    ].dropna()

    full_top5 = skyline_select(
        sample_full, req,
        benefit_cols=["metric_score","data_volume"],
        cost_cols=["cpu_time_s","cpu_utilization"],
        mapping={"min_accuracy":"metric_score","min_data_volume":"data_volume"}
    )

    print("\n---- TOP 5 FULL MLaaS ----")
    if not full_top5.empty:
        print(full_top5[["client_id","model_type","similarity"]].to_string(index=False))
        best_full = full_top5["similarity"].max()
    else:
        print("No candidates selected.")
        best_full = 0.0


    # ---------------- INCOMPLETE MLaaS ----------------
    sample_inc = df_incomp.sample(n=min(500, len(df_incomp)), random_state=42)[
        ["service_id","global_score","computation_time","data_volume"]
    ].dropna()

    inc_top5 = skyline_select(
        sample_inc, req,
        benefit_cols=["global_score","data_volume"],
        cost_cols=["computation_time"],
        mapping={"min_accuracy":"global_score", "min_data_volume":"data_volume"}
    )

    print("\n---- TOP 5 INCOMPLETE MLaaS ----")
    if not inc_top5.empty:
        print(inc_top5[["service_id","similarity"]].to_string(index=False))
        best_inc = inc_top5["similarity"].max()
    else:
        print("No candidates selected.")
        best_inc = 0.0


    # ---------------- QWS ----------------
    qws_sample = df_qws.sample(n=min(100, len(df_qws)), random_state=42)[
        ["success_rate","latency"]
    ].dropna()

    qws_sample["acc"] = qws_sample["success_rate"] / 100
    qws_sample["data"] = req["min_data_volume"]

    qws_top5 = skyline_select(
        qws_sample, req,
        benefit_cols=["acc"],
        cost_cols=["latency"],
        mapping={"min_accuracy":"acc"}
    )

    print("\n---- TOP 5 QWS ----")
    if not qws_top5.empty:
        print(qws_top5[["acc","similarity"]].to_string(index=False))
        best_qws = qws_top5["similarity"].max()
    else:
        print("No candidates selected.")
        best_qws = 0.0


    # ---------------- SUMMARY WINNER ----------------
    scores = {
        "Full MLaaS": best_full,
        "Incomplete MLaaS": best_inc,
        "QWS": best_qws
    }
    best_source = max(scores, key=scores.get)

    print("\n---- BEST MATCH SUMMARY ----")
    print(f" Full MLaaS best similarity       : {best_full:.4f}")
    print(f" Incomplete MLaaS best similarity : {best_inc:.4f}")
    print(f" QWS best similarity              : {best_qws:.4f}")
    print(f" => Best overall source: **{best_source}**")
    print("============================================================\n")

